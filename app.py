import streamlit as st
import time
import json
import re
from typing import List
import google.generativeai as genai
import PyPDF2

# ======================
# ğŸ” Gemini é…ç½®ï¼ˆå†™æ­»ï¼‰
# ======================
genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
MODEL_NAME = "gemini-2.5-flash"
TEMPERATURE = 0.1

# ======================
# ğŸŒ å¤šè¯­è¨€
# ======================
LANG = {
    "zh": {
        "title": "ğŸ“š æ™ºèƒ½è¯¾ç¨‹å¤ä¹ ç³»ç»Ÿ",
        "upload": "ä¸Šä¼ è¯¾ç¨‹PDFï¼ˆå¯å¤šä¸ªï¼Œâ‰¤200MBï¼‰",
        "start": "ğŸš€ å¼€å§‹åˆ†æ",
        "assistant": "ğŸ’¬ AIåŠ©æ•™",
        "ask": "è¾“å…¥ä½ çš„é—®é¢˜",
        "no_pdf": "âš ï¸ è¯·å…ˆä¸Šä¼ PDFæ–‡ä»¶",
        "uploaded": "å·²ä¸Šä¼ æ–‡ä»¶æ•°é‡",
        "processing": "å¤„ç†ä¸­...",
        "done": "âœ… åˆ†æå®Œæˆ",
    },
    "en": {
        "title": "ğŸ“š AI Course Review System",
        "upload": "Upload course PDFs (multiple, â‰¤200MB)",
        "start": "ğŸš€ Start Analysis",
        "assistant": "ğŸ’¬ AI Tutor",
        "ask": "Ask your question",
        "no_pdf": "âš ï¸ Please upload PDFs first",
        "uploaded": "Files uploaded",
        "processing": "Processing...",
        "done": "âœ… Completed",
    },
}

# ======================
# ğŸ§  Session åˆå§‹åŒ–
# ======================
for key, default in {
    "lang": "zh",
    "summary": "",
    "flashcards": [],
    "quiz": [],
}.items():
    if key not in st.session_state:
        st.session_state[key] = default

# ======================
# ğŸŒ è¯­è¨€åˆ‡æ¢
# ======================
lang_choice = st.sidebar.selectbox("Language / è¯­è¨€", ["ä¸­æ–‡", "English"])
st.session_state.lang = "zh" if lang_choice == "ä¸­æ–‡" else "en"
T = LANG[st.session_state.lang]

st.title(T["title"])

# ======================
# ğŸ“¥ PDF ä¸Šä¼ 
# ======================
uploaded_files = st.file_uploader(
    T["upload"],
    type=["pdf"],
    accept_multiple_files=True,
)

# â­â­â­ æ˜¾ç¤ºä¸Šä¼ æ•°é‡ï¼ˆä½ è¦æ±‚çš„åŠŸèƒ½ï¼‰
if uploaded_files:
    st.info(f"ğŸ“ {T['uploaded']}: **{len(uploaded_files)}**")

# ======================
# ğŸ”§ å·¥å…·å‡½æ•°
# ======================

def update_progress(progress_bar, percent_box, value):
    progress_bar.progress(value)
    percent_box.markdown(f"**{value}%**")


def extract_text_from_pdfs(files) -> str:
    all_text = []
    for file in files:
        try:
            reader = PyPDF2.PdfReader(file)
            for page in reader.pages:
                text = page.extract_text()
                if text and text.strip():
                    all_text.append(text)
        except Exception:
            st.warning(f"PDF è¯»å–å¤±è´¥: {file.name}")
    return "\n".join(all_text)


def chunk_text(text: str, chunk_size: int = 12000) -> List[str]:
    return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]


# â­â­â­ æŒ‡æ•°é€€é¿é‡è¯•ï¼ˆç»ˆæç¨³å®šï¼‰
def call_gemini(prompt: str, retries: int = 4) -> str:
    model = genai.GenerativeModel(MODEL_NAME)

    for i in range(retries):
        try:
            response = model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=TEMPERATURE,
                ),
            )
            return response.text

        except Exception as e:
            if "ResourceExhausted" in str(e) and i < retries - 1:
                wait_time = 2 ** i
                time.sleep(wait_time)
            else:
                raise e


def safe_json_load(text: str):
    try:
        text = re.sub(r"```json|```", "", text).strip()
        return json.loads(text)
    except Exception:
        return []


def determine_question_count(text_length: int) -> int:
    if text_length < 5000:
        return 5
    elif text_length < 15000:
        return 10
    elif text_length < 30000:
        return 15
    else:
        return 20


# â­â­â­ è¶…ç¨³ Reduceï¼ˆå·²å¼ºåŒ–ï¼‰
def reduce_summaries(summaries, batch_size=2):
    reduced = []

    for i in range(0, len(summaries), batch_size):
        batch = summaries[i:i + batch_size]
        batch_text = "\n".join(batch)

        # ğŸ”¥ é•¿åº¦ä¿æŠ¤
        if len(batch_text) > 12000:
            batch_text = batch_text[:12000]

        prompt = f"""
Condense the following study notes into a tight academic summary.
Be concise but keep key knowledge.

Notes:
{batch_text}
"""
        reduced_text = call_gemini(prompt)
        reduced.append(reduced_text)

        # ğŸ”¥ Cloud èŠ‚æµ
        time.sleep(1.2)

    return "\n".join(reduced)


# ======================
# ğŸš€ å¼€å§‹åˆ†æ
# ======================
if st.button(T["start"]):

    if not uploaded_files:
        st.warning(T["no_pdf"])
        st.stop()

    progress_bar = st.progress(0)
    percent_box = st.empty()
    status = st.empty()

    # Step 1
    status.text("ğŸ“¥ Reading PDFs...")
    update_progress(progress_bar, percent_box, 5)

    full_text = extract_text_from_pdfs(uploaded_files)

    if not full_text.strip():
        st.error("âŒ æœªèƒ½ä»PDFæå–æ–‡æœ¬ï¼ˆå¯èƒ½æ˜¯æ‰«æç‰ˆï¼‰")
        st.stop()

    # Step 2
    status.text("âœ‚ï¸ Chunking...")
    update_progress(progress_bar, percent_box, 15)

    chunks = chunk_text(full_text)

    # Step 3 MAP
    status.text("ğŸ§  AI analyzing...")
    update_progress(progress_bar, percent_box, 35)

    partial_summaries = []

    for idx, chunk in enumerate(chunks):
        prompt = f"""
You are an expert academic tutor.

Analyze the following course content and produce structured notes.

Content:
{chunk}
"""
        partial = call_gemini(prompt)
        partial_summaries.append(partial)

        # ğŸ”¥ èŠ‚æµï¼ˆæé‡è¦ï¼‰
        time.sleep(0.8)

    # Step 4 REDUCE
    status.text("ğŸ§© Compressing knowledge...")
    update_progress(progress_bar, percent_box, 55)

    compressed_text = reduce_summaries(partial_summaries)

    # Step 5 FINAL
    status.text("ğŸ“š Generating final review...")
    update_progress(progress_bar, percent_box, 75)

    final_prompt = f"""
You are a senior international curriculum teacher.

Create a HIGH-QUALITY exam review sheet.

STRICT STRUCTURE:

# Knowledge Explanation
# ğŸ”´ High-Frequency Exam Points
# ğŸŸ  Common Traps
# ğŸ§  Rapid Review Sheet

Content:
{compressed_text}
"""

    st.session_state.summary = call_gemini(final_prompt)

    # Step 6 Flashcards
    status.text("ğŸƒ Flashcards...")
    update_progress(progress_bar, percent_box, 90)

    q_count = determine_question_count(len(full_text))

    flash_prompt = f"""
Generate {q_count} high-quality flashcards.

Return ONLY JSON list:
[{{"q":"","a":""}}]

Content:
{compressed_text}
"""
    flash_raw = call_gemini(flash_prompt)
    st.session_state.flashcards = safe_json_load(flash_raw)

    # Step 7 Quiz
    status.text("ğŸ§ª Quiz...")
    update_progress(progress_bar, percent_box, 97)

    quiz_prompt = f"""
Generate {q_count} exam-style questions.

Mix:
- multiple choice
- true/false
- short answer

Return JSON list.

Content:
{compressed_text}
"""
    quiz_raw = call_gemini(quiz_prompt)
    st.session_state.quiz = safe_json_load(quiz_raw)

    update_progress(progress_bar, percent_box, 100)
    status.text(T["done"])

# ======================
# ğŸ“š æ˜¾ç¤ºæ€»ç»“
# ======================
if st.session_state.summary:
    st.markdown(st.session_state.summary, unsafe_allow_html=True)

# ======================
# ğŸƒ Flashcards
# ======================
if st.session_state.flashcards:
    st.subheader("ğŸƒ Flashcards")
    for i, card in enumerate(st.session_state.flashcards):
        with st.expander(f"Card {i+1}"):
            st.write("**Q:**", card.get("q", ""))
            st.write("**A:**", card.get("a", ""))

# ======================
# ğŸ§ª Quiz
# ======================
if st.session_state.quiz:
    st.subheader("ğŸ§ª Quiz")
    st.json(st.session_state.quiz)

# ======================
# ğŸ’¬ AI åŠ©æ•™
# ======================
st.divider()
st.subheader(T["assistant"])

user_q = st.text_input(T["ask"])

if user_q and st.session_state.summary:
    tutor_prompt = f"""
You are a course tutor.

Answer based ONLY on the course content below.

Course:
{st.session_state.summary}

Question:
{user_q}
"""
    answer = call_gemini(tutor_prompt)
    st.write(answer)