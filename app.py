import streamlit as st
import google.generativeai as genai
from pypdf import PdfReader
import time
import random

# ==========================================
# 1. æ ¸å¿ƒæ¨¡å‹é”å®š (å¼ºåˆ¶ç¡¬ç¼–ç )
# ==========================================
TARGET_MODEL = "gemini-2.5-flash"

# ==========================================
# 2. é¡µé¢ä¸è§†è§‰æ¶æ„ (æè‡´éšè—ä¾§è¾¹æ )
# ==========================================
st.set_page_config(
    page_title="AI International Course System",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# å¼ºåŠ› CSS æ³¨å…¥ï¼šéšè—ä¾§è¾¹æ ã€ç¾åŒ–ç•Œé¢ã€å®šåˆ¶é«˜äº®
st.markdown("""
    <style>
        /* å½»åº•æ¶ˆé™¤ä¾§è¾¹æ åŠå…¶å ä½ */
        [data-testid="stSidebar"], [data-testid="stSidebarNav"], section[data-testid="stSidebar"] {
            display: none !important;
            width: 0px !important;
        }
        /* ç§»é™¤é¡¶éƒ¨å¤šä½™ç©ºç™½ */
        .block-container {
            padding-top: 1.5rem !important;
            padding-bottom: 1rem !important;
        }
        /* å³ä¸Šè§’æŒ‰é’®ç¾åŒ– */
        .stButton button {
            border-radius: 12px;
            font-weight: 600;
        }
        /* å¤ä¹ é‡ç‚¹å— - æ©™è‰²è­¦ç¤ºé£æ ¼ */
        .revision-highlight {
            background-color: #fff9db;
            border-left: 5px solid #fcc419;
            padding: 1.5rem;
            border-radius: 8px;
            color: #444;
            margin: 10px 0;
        }
        /* é—ªå¡å¡ç‰‡é£æ ¼ */
        .flashcard {
            background-color: #f8f9fa;
            border: 1px solid #dee2e6;
            padding: 1rem;
            border-radius: 10px;
            margin-bottom: 0.5rem;
            border-bottom: 3px solid #339af0;
        }
        /* éšè— Streamlit é»˜è®¤é¡µè„š */
        footer {visibility: hidden;}
    </style>
""", unsafe_allow_html=True)

# ==========================================
# 3. å¤šè¯­è¨€æ”¯æŒç³»ç»Ÿ (Session State)
# ==========================================
if 'lang' not in st.session_state:
    st.session_state.lang = 'CN'
if 'result_raw' not in st.session_state:
    st.session_state.result_raw = None
if 'file_key' not in st.session_state:
    st.session_state.file_key = 0
if 'chat_msgs' not in st.session_state:
    st.session_state.chat_msgs = []

# å®šä¹‰å…¨é‡æ–‡æœ¬æ˜ å°„
DIC = {
    'CN': {
        'toggle': "English Version",
        'title': "ğŸ“ å›½é™…å­¦æ ¡è¯¾ç¨‹ AI æ™ºèƒ½åˆ†æç»ˆç«¯",
        'up_label': "è¯·ä¸Šä¼ è¯¾ç¨‹ PDF æ•™æ (æ”¯æŒå¤šä¸ªæ–‡ä»¶åŒæ—¶ä¸Šä¼ )",
        'up_success': "âœ… æˆåŠŸè½½å…¥ {} ä¸ªå­¦æœ¯æ–‡ä»¶",
        'clear': "ğŸ—‘ï¸ ä¸€é”®æ¸…é™¤æ‰€æœ‰æ–‡ä»¶",
        'analyze': "å¼€å§‹æ·±åº¦åˆ†æè¯¾ç¨‹ (AI å‘èµ·)",
        'step_read': "æ­£åœ¨è¯»å– PDF æ–‡æœ¬å†…å®¹...",
        'step_ai': "æ­£åœ¨è°ƒç”¨ Gemini 2.5 Flash è¿›è¡Œå­¦æœ¯å½’çº³...",
        'eta': "é¢„è®¡è¿›åº¦: {}% | å‰©ä½™çº¦ {} ç§’",
        'finish': "åˆ†æä»»åŠ¡åœ†æ»¡å®Œæˆï¼",
        'tab1': "ğŸ“– å­¦ä¹ ç†è§£",
        'tab2': "ğŸ“ å¤ä¹ å¤‡è€ƒ",
        'tab3': "ğŸƒ é—ªå¡è®­ç»ƒ",
        'tab4': "âœï¸ è‡ªæµ‹é¢˜ç›®",
        'tab5': "ğŸ¤– AI åŠ©æ•™",
        'chat_input': "è¾“å…¥é—®é¢˜ï¼Œå’¨è¯¢æ‚¨çš„ AI åŠ©æ•™...",
        'error_api': "API è°ƒç”¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¯†é’¥æˆ–ç½‘ç»œçŠ¶æ€ã€‚",
        'prompt_role': f"ä½ æ˜¯ä¸€åæ‹¥æœ‰30å¹´ç»éªŒçš„å›½é™…å­¦æ ¡æ•™åŠ¡ä¸»ä»»ï¼Œç²¾é€š IB, A-Level, AP, IGCSE ç­‰è¯¾ç¨‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºä¸Šä¼ çš„æ•™æï¼Œç”Ÿæˆä¸€ä»½æå…¶ä¸“ä¸šçš„å­¦ä¹ å¤ä¹ æŠ¥å‘Šã€‚å¿…é¡»ä½¿ç”¨ä¸­æ–‡ã€‚æ¨¡å‹é”å®šï¼š{TARGET_MODEL}"
    },
    'EN': {
        'toggle': "åˆ‡æ¢è‡³ä¸­æ–‡",
        'title': "ğŸ“ AI International Course Analytics Terminal",
        'up_label': "Upload Course PDF Materials (Multiple files supported)",
        'up_success': "âœ… {} academic files loaded successfully",
        'clear': "ğŸ—‘ï¸ Clear and Restart",
        'analyze': "Start Deep Analysis (AI Trigger)",
        'step_read': "Reading PDF text content...",
        'step_ai': "Analyzing with Gemini 2.5 Flash...",
        'eta': "Progress: {}% | ETA: {}s",
        'finish': "Analysis Task Completed!",
        'tab1': "ğŸ“– Understanding",
        'tab2': "ğŸ“ Revision",
        'tab3': "ğŸƒ Flashcards",
        'tab4': "âœï¸ Self-Test",
        'tab5': "ğŸ¤– AI Assistant",
        'chat_input': "Ask your AI tutor anything...",
        'error_api': "API call failed. Please check your credentials.",
        'prompt_role': f"You are a senior Academic Director with 30 years of experience in IB, A-Level, AP, etc. Your task is to generate a highly professional review report based on the provided materials. MUST BE IN ENGLISH. Model: {TARGET_MODEL}"
    }
}

ui = DIC[st.session_state.lang]

# ==========================================
# 4. å¤´éƒ¨å¯¼èˆª (å³ä¸Šè§’åˆ‡æ¢è¯­è¨€)
# ==========================================
h_col1, h_col2 = st.columns([0.8, 0.2])
with h_col1:
    st.title(ui['title'])
with h_col2:
    if st.button(ui['toggle'], use_container_width=True):
        st.session_state.lang = 'EN' if st.session_state.lang == 'CN' else 'CN'
        st.rerun()

st.divider()

# ==========================================
# 5. ä¸Šä¼ ç®¡ç†åŒº
# ==========================================
pdf_inputs = st.file_uploader(
    ui['up_label'],
    type=['pdf'],
    accept_multiple_files=True,
    key=f"uploader_{st.session_state.file_key}"
)

if pdf_inputs:
    info_c, ctrl_c = st.columns([0.7, 0.3])
    with info_c:
        st.success(ui['up_success'].format(len(pdf_inputs)))
    with ctrl_c:
        if st.button(ui['clear'], use_container_width=True):
            st.session_state.file_key += 1
            st.session_state.result_raw = None
            st.session_state.chat_msgs = []
            st.rerun()

# ==========================================
# 6. å­¦æœ¯åˆ†æå¼•æ“ (PDF å¤„ç† + API è°ƒç”¨)
# ==========================================
def perform_academic_analysis(files):
    # æå–æ–‡æœ¬
    combined_text = ""
    for f in files:
        reader = PdfReader(f)
        for page in reader.pages:
            combined_text += (page.extract_text() or "") + "\n"
    
    # å‡†å¤‡ API
    try:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
        model = genai.GenerativeModel(TARGET_MODEL)
        
        # ç²¾å¿ƒè®¾è®¡çš„ç³»ç»Ÿ Promptï¼Œç¡®ä¿äº”ä¸ªæ¨¡å—è¢«æ ‡è®°ï¼Œæ–¹ä¾¿åˆ‡åˆ†
        sys_prompt = f"""
        {ui['prompt_role']}
        
        è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼Œä¸è¦åŒ…å«å¤šä½™çš„å¼€åœºç™½ï¼š
        ---SECTION_1---
        (æ­¤å¤„ä¸ºå­¦ä¹ ç†è§£æ¨¡å—ï¼šç®€æ´å½’çº³æ ¸å¿ƒå†…å®¹ï¼Œå¤šä½¿ç”¨å±‚çº§ç¬¦å·)
        ---SECTION_2---
        (æ­¤å¤„ä¸ºå¤ä¹ å¤‡è€ƒæ¨¡å—ï¼šæŠ“å–é‡éš¾ç‚¹ã€‚å¯¹æœ€å…³é”®çš„çŸ¥è¯†ç‚¹è¯·ç”¨ ğŸ’¡ æ ‡æ³¨å¹¶åŠ ç²—ã€‚å…³é”®æœ¯è¯­å¿…é¡»çªå‡ºã€‚)
        ---SECTION_3---
        (æ­¤å¤„ä¸ºé—ªå¡éƒ¨åˆ†ï¼š5-20ä¸ªé—ªå¡ã€‚æ ¼å¼ï¼šQ: [é—®é¢˜] | A: [ç­”æ¡ˆ])
        ---SECTION_4---
        (æ­¤å¤„ä¸ºè‡ªæµ‹éƒ¨åˆ†ï¼š10-20é¢˜ï¼ŒåŒ…å«å„ç§é¢˜å‹ï¼Œæœ€åé™„ä¸Šç­”æ¡ˆ)
        ---END---
        
        å¾…åˆ†ææ•™æå†…å®¹ï¼š
        {combined_text[:35000]}
        """
        
        response = model.generate_content(sys_prompt)
        return response.text
    except Exception as e:
        st.error(f"{ui['error_api']} : {str(e)}")
        return None

# ==========================================
# 7. è¿›åº¦åé¦ˆä¸æ‰§è¡Œé€»è¾‘
# ==========================================
if pdf_inputs and st.button(ui['analyze'], type="primary", use_container_width=True):
    bar = st.progress(0)
    msg_slot = st.empty()
    eta_slot = st.empty()
    
    # æ­¥éª¤ 1: è¯»å–
    msg_slot.info(ui['step_read'])
    time.sleep(1) # å¢åŠ ç‰©ç†è¯»å–æ„Ÿ
    bar.progress(10)
    
    # æ­¥éª¤ 2: è°ƒç”¨ AI
    msg_slot.info(ui['step_ai'])
    
    # å¼€å¯æ¨¡æ‹Ÿå€’è®¡æ—¶
    start_time = time.time()
    total_expected = 25 # é¢„ä¼°å¤„ç†æ—¶é—´
    
    # çœŸå® API è¯·æ±‚
    raw_output = perform_academic_analysis(pdf_inputs)
    
    # æ¨¡æ‹Ÿå¹³æ»‘è¿›åº¦æ¡
    for i in range(11, 101):
        elapsed = time.time() - start_time
        remain = max(1, total_expected - int(elapsed))
        bar.progress(i)
        eta_slot.write(ui['eta'].format(i, remain))
        time.sleep(0.05) if i < 90 else time.sleep(0.01)
        
    if raw_output:
        st.session_state.result_raw = raw_output
        msg_slot.success(ui['finish'])
        eta_slot.empty()
        time.sleep(1)
        st.rerun()

# ==========================================
# 8. æˆæœå±•ç¤ºåŒº (å­¦æœ¯æŠ¥å‘Š Tabs)
# ==========================================
if st.session_state.result_raw:
    raw = st.session_state.result_raw
    
    # ç¨³å¥çš„åˆ‡åˆ†é€»è¾‘
    try:
        s1 = raw.split("---SECTION_1---")[1].split("---SECTION_2---")[0]
        s2 = raw.split("---SECTION_2---")[1].split("---SECTION_3---")[0]
        s3 = raw.split("---SECTION_3---")[1].split("---SECTION_4---")[0]
        s4 = raw.split("---SECTION_4---")[1].split("---END---")[0]
    except:
        s1, s2, s3, s4 = raw, "Error", "Error", "Error"

    tab1, tab2, tab3, tab4, tab5 = st.tabs([ui['tab1'], ui['tab2'], ui['tab3'], ui['tab4'], ui['tab5']])
    
    with tab1:
        st.markdown(s1)
    
    with tab2:
        # ä½¿ç”¨è‡ªå®šä¹‰ CSS ç±»æ¥ç¾åŒ–å¤ä¹ é‡ç‚¹
        st.markdown(f'<div class="revision-highlight">{s2}</div>', unsafe_allow_html=True)
        
    with tab3:
        # é—ªå¡éƒ¨åˆ†ç¾åŒ–
        cards = s3.strip().split("\n")
        for card in cards:
            if "|" in card:
                st.markdown(f'<div class="flashcard">{card}</div>', unsafe_allow_html=True)
            else:
                st.write(card)
                
    with tab4:
        st.markdown(s4)
        
    with tab5:
        st.subheader(ui['tab5'])
        # å¯¹è¯å®¹å™¨
        for m in st.session_state.chat_msgs:
            with st.chat_message(m["role"]):
                st.write(m["content"])
        
        if q := st.chat_input(ui['chat_input']):
            st.session_state.chat_msgs.append({"role": "user", "content": q})
            with st.chat_message("user"):
                st.write(q)
            
            with st.chat_message("assistant"):
                m_chat = genai.GenerativeModel(TARGET_MODEL)
                # æ³¨å…¥ä¸Šä¸‹æ–‡è¿›è¡Œå¯¹è¯
                context = f"Context Material: {s1[:3000]}\nUser Question: {q}"
                resp = m_chat.generate_content(context)
                st.write(resp.text)
                st.session_state.chat_msgs.append({"role": "assistant", "content": resp.text})